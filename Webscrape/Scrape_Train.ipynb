{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WYQlLdooYaUs",
        "outputId": "bc26c9e2-9eb9-45c5-ce7d-675833d26e31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.83)] [Connected to cloud.r-pr\r                                                                               \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "chromium-chromedriver is already the newest version (1:85.0.4183.83-0ubuntu2.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.11/dist-packages (4.34.2)\n",
            "Requirement already satisfied: urllib3~=2.5.0 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]~=2.5.0->selenium) (2.5.0)\n",
            "Requirement already satisfied: trio~=0.30.0 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.30.0)\n",
            "Requirement already satisfied: trio-websocket~=0.12.2 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.12.2)\n",
            "Requirement already satisfied: certifi>=2025.6.15 in /usr/local/lib/python3.11/dist-packages (from selenium) (2025.7.14)\n",
            "Requirement already satisfied: typing_extensions~=4.14.0 in /usr/local/lib/python3.11/dist-packages (from selenium) (4.14.1)\n",
            "Requirement already satisfied: websocket-client~=1.8.0 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (25.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (3.10)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (1.3.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.11/dist-packages (from trio-websocket~=0.12.2->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]~=2.5.0->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.16.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.3.0)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "!apt-get update\n",
        "!apt-get install -y chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "!pip install selenium\n",
        "!pip install pillow\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.common.by import By\n",
        "import time\n",
        "import os\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from urllib.parse import urlparse"
      ],
      "metadata": {
        "id": "JMuejXAseL8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9k4mVhZoYdHE"
      },
      "outputs": [],
      "source": [
        "save_dir = \"/content/drive/MyDrive/scraped_images_pal\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "driver = webdriver.Chrome(options=options)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LofXvUf_YsAD"
      },
      "outputs": [],
      "source": [
        "def clean_url(url):\n",
        "    return url.split(\"?\")[0]\n",
        "\n",
        "def scroll_and_collect(driver, num_needed, collected_urls):\n",
        "    while len(collected_urls) < num_needed:\n",
        "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "        time.sleep(2)\n",
        "        images = driver.find_elements(By.TAG_NAME, \"img\")\n",
        "        for img in images:\n",
        "            srcset = img.get_attribute(\"srcset\")\n",
        "            if srcset:\n",
        "                highest_res = srcset.strip().split(\",\")[-1].split()[0]\n",
        "                cleaned = clean_url(highest_res)\n",
        "                collected_urls.add(cleaned)\n",
        "        print(f\"Collected: {len(collected_urls)} URLs\")\n",
        "    return collected_urls\n",
        "\n",
        "def download_images(urls, save_dir, batch_num, resize_dim=(256, 256)):\n",
        "    count = 0\n",
        "    for i, url in enumerate(urls):\n",
        "        try:\n",
        "            img_data = requests.get(url, timeout=10).content\n",
        "            img = Image.open(BytesIO(img_data)).convert(\"RGB\")\n",
        "            img = img.resize(resize_dim)\n",
        "            img.save(os.path.join(save_dir, f\"batch{batch_num}_{i}.jpg\"))\n",
        "            count += 1\n",
        "        except:\n",
        "            pass\n",
        "    print(f\"Downloaded {count} images in batch {batch_num}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-jELPDSayFJ",
        "outputId": "44ae657f-ed08-4e39-ec90-aa0468312793"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting batch 1\n",
            "Collected: 90 URLs\n",
            "Collected: 108 URLs\n",
            "Collected: 129 URLs\n",
            "Collected: 143 URLs\n",
            "Collected: 160 URLs\n",
            "Collected: 179 URLs\n",
            "Collected: 196 URLs\n",
            "Collected: 217 URLs\n",
            "Collected: 234 URLs\n",
            "Collected: 252 URLs\n",
            "Collected: 270 URLs\n",
            "Collected: 285 URLs\n",
            "Collected: 303 URLs\n",
            "Collected: 338 URLs\n",
            "Collected: 353 URLs\n",
            "Collected: 369 URLs\n",
            "Collected: 384 URLs\n",
            "Collected: 397 URLs\n",
            "Collected: 415 URLs\n",
            "Collected: 432 URLs\n",
            "Collected: 446 URLs\n",
            "Collected: 463 URLs\n",
            "Collected: 492 URLs\n",
            "Collected: 506 URLs\n",
            "Collected: 520 URLs\n",
            "Collected: 534 URLs\n",
            "Collected: 562 URLs\n",
            "Collected: 576 URLs\n",
            "Collected: 593 URLs\n",
            "Collected: 608 URLs\n",
            "Collected: 621 URLs\n",
            "Collected: 633 URLs\n",
            "Collected: 647 URLs\n",
            "Collected: 664 URLs\n",
            "Collected: 682 URLs\n",
            "Collected: 695 URLs\n",
            "Collected: 708 URLs\n",
            "Collected: 721 URLs\n",
            "Collected: 737 URLs\n",
            "Collected: 763 URLs\n",
            "Collected: 790 URLs\n",
            "Collected: 806 URLs\n",
            "Collected: 820 URLs\n",
            "Collected: 834 URLs\n",
            "Collected: 847 URLs\n",
            "Collected: 862 URLs\n",
            "Collected: 877 URLs\n",
            "Collected: 891 URLs\n",
            "Collected: 919 URLs\n",
            "Collected: 937 URLs\n",
            "Collected: 951 URLs\n",
            "Collected: 966 URLs\n",
            "Collected: 976 URLs\n",
            "Collected: 991 URLs\n",
            "Collected: 1005 URLs\n",
            "Collected: 1021 URLs\n",
            "Collected: 1036 URLs\n",
            "Collected: 1050 URLs\n",
            "Collected: 1063 URLs\n",
            "Collected: 1091 URLs\n",
            "Collected: 1104 URLs\n",
            "Collected: 1116 URLs\n",
            "Collected: 1143 URLs\n",
            "Collected: 1156 URLs\n",
            "Collected: 1171 URLs\n",
            "Collected: 1186 URLs\n",
            "Collected: 1199 URLs\n",
            "Collected: 1229 URLs\n",
            "Collected: 1244 URLs\n",
            "Collected: 1256 URLs\n",
            "Collected: 1272 URLs\n",
            "Collected: 1297 URLs\n",
            "Collected: 1313 URLs\n",
            "Collected: 1328 URLs\n",
            "Collected: 1355 URLs\n",
            "Collected: 1366 URLs\n",
            "Collected: 1385 URLs\n",
            "Collected: 1397 URLs\n",
            "Collected: 1410 URLs\n",
            "Collected: 1438 URLs\n",
            "Collected: 1450 URLs\n",
            "Collected: 1463 URLs\n",
            "Collected: 1477 URLs\n",
            "Collected: 1492 URLs\n",
            "Collected: 1505 URLs\n",
            "Collected: 1519 URLs\n",
            "Collected: 1530 URLs\n",
            "Collected: 1542 URLs\n",
            "Collected: 1553 URLs\n",
            "Collected: 1570 URLs\n",
            "Collected: 1583 URLs\n",
            "Collected: 1595 URLs\n",
            "Collected: 1606 URLs\n",
            "Collected: 1621 URLs\n",
            "Collected: 1635 URLs\n",
            "Collected: 1649 URLs\n",
            "Collected: 1661 URLs\n",
            "Collected: 1690 URLs\n",
            "Collected: 1706 URLs\n",
            "Collected: 1721 URLs\n",
            "Collected: 1759 URLs\n",
            "Collected: 1773 URLs\n",
            "Collected: 1786 URLs\n",
            "Collected: 1814 URLs\n",
            "Collected: 1826 URLs\n",
            "Collected: 1854 URLs\n",
            "Collected: 1867 URLs\n",
            "Collected: 1895 URLs\n",
            "Collected: 1908 URLs\n",
            "Collected: 1923 URLs\n",
            "Collected: 1952 URLs\n",
            "Collected: 1964 URLs\n",
            "Collected: 1978 URLs\n",
            "Collected: 1991 URLs\n",
            "Collected: 2004 URLs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:3452: DecompressionBombWarning: Image size (101756928 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:3452: DecompressionBombWarning: Image size (102172140 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:3452: DecompressionBombWarning: Image size (111065900 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:3452: DecompressionBombWarning: Image size (103833600 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloaded 2003 images in batch 1\n",
            "Starting batch 2\n",
            "Collected: 2020 URLs\n",
            "Downloaded 2019 images in batch 2\n",
            "Starting batch 3\n",
            "Collected: 2034 URLs\n",
            "Downloaded 2034 images in batch 3\n",
            "Starting batch 4\n",
            "Collected: 2059 URLs\n",
            "Downloaded 2059 images in batch 4\n",
            "Starting batch 5\n",
            "Collected: 2072 URLs\n",
            "Downloaded 2072 images in batch 5\n",
            "Starting batch 6\n",
            "Collected: 2085 URLs\n",
            "Downloaded 2085 images in batch 6\n",
            "Starting batch 7\n",
            "Collected: 2100 URLs\n",
            "Downloaded 2100 images in batch 7\n",
            "Starting batch 8\n",
            "Collected: 2111 URLs\n",
            "Downloaded 2111 images in batch 8\n",
            "Starting batch 9\n",
            "Collected: 2122 URLs\n",
            "Downloaded 2122 images in batch 9\n",
            "Starting batch 10\n",
            "Collected: 2134 URLs\n",
            "Downloaded 2134 images in batch 10\n",
            "Starting batch 11\n",
            "Collected: 2160 URLs\n",
            "Downloaded 2160 images in batch 11\n",
            "Starting batch 12\n",
            "Collected: 2172 URLs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:3452: DecompressionBombWarning: Image size (96000000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloaded 2172 images in batch 12\n",
            "Starting batch 13\n",
            "Collected: 2187 URLs\n",
            "Downloaded 2187 images in batch 13\n",
            "Starting batch 14\n",
            "Collected: 2212 URLs\n",
            "Downloaded 2212 images in batch 14\n",
            "Starting batch 15\n",
            "Collected: 2226 URLs\n",
            "Downloaded 2226 images in batch 15\n",
            "Starting batch 16\n",
            "Collected: 2242 URLs\n",
            "Downloaded 2242 images in batch 16\n",
            "Starting batch 17\n",
            "Collected: 2266 URLs\n",
            "Downloaded 2266 images in batch 17\n",
            "Starting batch 18\n",
            "Collected: 2294 URLs\n",
            "Downloaded 2294 images in batch 18\n",
            "Starting batch 19\n",
            "Collected: 2307 URLs\n",
            "Downloaded 2307 images in batch 19\n",
            "Starting batch 20\n",
            "Collected: 2329 URLs\n",
            "Downloaded 2329 images in batch 20\n",
            "Starting batch 21\n"
          ]
        }
      ],
      "source": [
        "driver.get(\"https://unsplash.com\")\n",
        "total_images = 44000\n",
        "batch_size = 2000\n",
        "\n",
        "for batch in range(1, (total_images // batch_size) + 1):\n",
        "    print(f\"Starting batch {batch}\")\n",
        "    image_urls = set()\n",
        "    image_urls = scroll_and_collect(driver, batch_size, image_urls)\n",
        "    download_images(list(image_urls), save_dir, batch_num=batch)\n",
        "    time.sleep(5)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
