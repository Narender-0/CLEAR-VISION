{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 12738568,
          "sourceType": "datasetVersion",
          "datasetId": 8052236
        },
        {
          "sourceId": 12787398,
          "sourceType": "datasetVersion",
          "datasetId": 8084578
        }
      ],
      "dockerImageVersionId": 31089,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-17T12:39:10.540154Z",
          "iopub.execute_input": "2025-08-17T12:39:10.540803Z",
          "iopub.status.idle": "2025-08-17T12:41:55.221479Z",
          "shell.execute_reply.started": "2025-08-17T12:39:10.540780Z",
          "shell.execute_reply": "2025-08-17T12:41:55.220830Z"
        },
        "id": "t-qCK5xKia7G"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "!pip install lpips"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-17T18:46:09.397977Z",
          "iopub.execute_input": "2025-08-17T18:46:09.398602Z",
          "iopub.status.idle": "2025-08-17T18:47:20.282033Z",
          "shell.execute_reply.started": "2025-08-17T18:46:09.398578Z",
          "shell.execute_reply": "2025-08-17T18:47:20.281205Z"
        },
        "id": "YzMnXGZSia7K"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install piq"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-17T18:47:20.283351Z",
          "iopub.execute_input": "2025-08-17T18:47:20.283634Z",
          "iopub.status.idle": "2025-08-17T18:47:26.448564Z",
          "shell.execute_reply.started": "2025-08-17T18:47:20.283610Z",
          "shell.execute_reply": "2025-08-17T18:47:26.447770Z"
        },
        "id": "gd4BH0Goia7L"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import time\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import lpips\n",
        "import torch.nn.functional as F\n",
        "from piq import SSIMLoss, MultiScaleSSIMLoss\n",
        "from torchmetrics.functional import peak_signal_noise_ratio as psnr"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-17T18:47:26.449451Z",
          "iopub.execute_input": "2025-08-17T18:47:26.449647Z",
          "iopub.status.idle": "2025-08-17T18:47:37.044235Z",
          "shell.execute_reply.started": "2025-08-17T18:47:26.449625Z",
          "shell.execute_reply": "2025-08-17T18:47:37.043643Z"
        },
        "id": "Nesba6lSia7M"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-17T18:47:37.045791Z",
          "iopub.execute_input": "2025-08-17T18:47:37.046155Z",
          "iopub.status.idle": "2025-08-17T18:47:37.132694Z",
          "shell.execute_reply.started": "2025-08-17T18:47:37.046137Z",
          "shell.execute_reply": "2025-08-17T18:47:37.131975Z"
        },
        "id": "9dxCh-TLia7N"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# define custom dataset class\n",
        "\n",
        "class ImageRestorationDataset(Dataset):\n",
        "\n",
        "  def __init__(self, corrupted_dir, clean_dir, transform=None):\n",
        "    self.corrupted_dir = corrupted_dir\n",
        "    self.clean_dir = clean_dir\n",
        "    self.transform = transform\n",
        "\n",
        "    # get sorted list of image file names from the corrupted image folder\n",
        "    self.filenames = sorted(os.listdir(corrupted_dir))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.filenames)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "    # get file paths\n",
        "    corrupted_path = os.path.join(self.corrupted_dir, self.filenames[idx])\n",
        "    clean_path = os.path.join(self.clean_dir, self.filenames[idx])\n",
        "\n",
        "\n",
        "    # open images and convert to RGB format\n",
        "    corrupted_image = Image.open(corrupted_path).convert(\"RGB\")\n",
        "    clean_image = Image.open(clean_path).convert(\"RGB\")\n",
        "\n",
        "    if self.transform:\n",
        "      corrupted_image = self.transform(corrupted_image)\n",
        "      clean_image = self.transform(clean_image)\n",
        "\n",
        "    return corrupted_image, clean_image"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-17T18:47:37.133481Z",
          "iopub.execute_input": "2025-08-17T18:47:37.133741Z",
          "iopub.status.idle": "2025-08-17T18:47:37.148478Z",
          "shell.execute_reply.started": "2025-08-17T18:47:37.133714Z",
          "shell.execute_reply": "2025-08-17T18:47:37.147854Z"
        },
        "id": "IKHANLDmia7O"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert PIL Image to PyTorch Tensor\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Normalize to [-1, 1]\n",
        "])\n",
        "\n",
        "val_clean_dir = '/kaggle/input/clearvision-image-dataset/val_clean_images'\n",
        "val_corrupted_dir = '/kaggle/input/clearvision-image-dataset/val_corrupted_images'\n",
        "\n",
        "# Validation dataset\n",
        "val_dataset = ImageRestorationDataset(val_corrupted_dir, val_clean_dir, transform=transform)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-17T18:47:37.149156Z",
          "iopub.execute_input": "2025-08-17T18:47:37.149679Z",
          "iopub.status.idle": "2025-08-17T18:47:37.300615Z",
          "shell.execute_reply.started": "2025-08-17T18:47:37.149661Z",
          "shell.execute_reply": "2025-08-17T18:47:37.300159Z"
        },
        "id": "CS4QRStRia7O"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(channels)\n",
        "        )\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.relu(x + self.block(x))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-17T18:47:37.301267Z",
          "iopub.execute_input": "2025-08-17T18:47:37.301499Z",
          "iopub.status.idle": "2025-08-17T18:47:37.306255Z",
          "shell.execute_reply.started": "2025-08-17T18:47:37.301479Z",
          "shell.execute_reply": "2025-08-17T18:47:37.305586Z"
        },
        "id": "6FXK3cYxia7P"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class UNetGenerator(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=3, features=64):\n",
        "        super(UNetGenerator, self).__init__()\n",
        "\n",
        "        # Encoder with residuals\n",
        "        self.down1 = nn.Sequential(self._contract_block(in_channels, features, use_batchnorm=False), ResidualBlock(features))\n",
        "        self.down2 = nn.Sequential(self._contract_block(features, features*2), ResidualBlock(features*2))\n",
        "        self.down3 = nn.Sequential(self._contract_block(features*2, features*4), ResidualBlock(features*4))\n",
        "        self.down4 = nn.Sequential(self._contract_block(features*4, features*8), ResidualBlock(features*8))\n",
        "\n",
        "        # Decoder with residuals\n",
        "        self.up1 = nn.Sequential(self._expand_block(features*8, features*4), ResidualBlock(features*4))\n",
        "        self.up2 = nn.Sequential(self._expand_block(features*8, features*2), ResidualBlock(features*2))\n",
        "        self.up3 = nn.Sequential(self._expand_block(features*4, features), ResidualBlock(features))\n",
        "\n",
        "        self.final = nn.Sequential(\n",
        "            nn.ConvTranspose2d(features*2, out_channels, kernel_size=4, stride=2, padding=1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def _contract_block(self, in_channels, out_channels, kernel_size=4, stride=2, padding=1, use_batchnorm=True):\n",
        "        layers = [nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)]\n",
        "        if use_batchnorm:\n",
        "            layers.append(nn.BatchNorm2d(out_channels))\n",
        "        layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _expand_block(self, in_channels, out_channels, kernel_size=4, stride=2, padding=1):\n",
        "        return nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        d1 = self.down1(x)\n",
        "        d2 = self.down2(d1)\n",
        "        d3 = self.down3(d2)\n",
        "        d4 = self.down4(d3)\n",
        "\n",
        "        u1 = self.up1(d4)\n",
        "        u2 = self.up2(torch.cat([u1, d3], dim=1))\n",
        "        u3 = self.up3(torch.cat([u2, d2], dim=1))\n",
        "\n",
        "        output = self.final(torch.cat([u3, d1], dim=1))\n",
        "        return output"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-17T18:47:37.306955Z",
          "iopub.execute_input": "2025-08-17T18:47:37.307140Z",
          "iopub.status.idle": "2025-08-17T18:47:37.318550Z",
          "shell.execute_reply.started": "2025-08-17T18:47:37.307118Z",
          "shell.execute_reply": "2025-08-17T18:47:37.317837Z"
        },
        "id": "maNnAaJYia7P"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "generator = UNetGenerator().to(device)\n",
        "generator.load_state_dict(torch.load('/kaggle/input/gan-checkpoints/final_generator_best.pth', map_location=device))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-17T18:47:37.319287Z",
          "iopub.execute_input": "2025-08-17T18:47:37.319497Z",
          "iopub.status.idle": "2025-08-17T18:47:38.241407Z",
          "shell.execute_reply.started": "2025-08-17T18:47:37.319483Z",
          "shell.execute_reply": "2025-08-17T18:47:38.240625Z"
        },
        "id": "aBVFK3mLia7Q",
        "outputId": "f2af30f7-7a7e-45e0-f492-b1bd8ff0f4a2"
      },
      "outputs": [
        {
          "execution_count": 9,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<All keys matched successfully>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# losses\n",
        "\n",
        "# Loss functions and optimizers\n",
        "adversarial_loss = torch.nn.BCEWithLogitsLoss()\n",
        "pixelwise_loss   = torch.nn.L1Loss()\n",
        "\n",
        "# Perceptual alternatives\n",
        "ssim_loss        = SSIMLoss(data_range=2.0).to(device)         # outputs are in [-1,1]\n",
        "ms_ssim_loss     = MultiScaleSSIMLoss(data_range=2.0).to(device)\n",
        "lpips_model = lpips.LPIPS(net='alex').to(device)\n",
        "lpips_model.eval()\n",
        "\n",
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "scaler_G = torch.cuda.amp.GradScaler()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-17T18:47:38.243406Z",
          "iopub.execute_input": "2025-08-17T18:47:38.243621Z",
          "iopub.status.idle": "2025-08-17T18:47:40.317442Z",
          "shell.execute_reply.started": "2025-08-17T18:47:38.243605Z",
          "shell.execute_reply": "2025-08-17T18:47:40.316671Z"
        },
        "id": "dERx04C1ia7S",
        "outputId": "8469762e-5be1-4cf2-d98c-491c0d63f8e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n100%|██████████| 233M/233M [00:01<00:00, 202MB/s] \n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Loading model from: /usr/local/lib/python3.11/dist-packages/lpips/weights/v0.1/alex.pth\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_36/4087878145.py:14: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler_G = torch.cuda.amp.GradScaler()\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "gen_dir = '/kaggle/working/generated'\n",
        "os.makedirs(gen_dir, exist_ok=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-17T18:47:40.318463Z",
          "iopub.execute_input": "2025-08-17T18:47:40.318737Z",
          "iopub.status.idle": "2025-08-17T18:47:40.322261Z",
          "shell.execute_reply.started": "2025-08-17T18:47:40.318713Z",
          "shell.execute_reply": "2025-08-17T18:47:40.321645Z"
        },
        "id": "A9za3cWPia7T"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def rescale_to_01(x):\n",
        "    return (x + 1) / 2"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-17T18:47:40.322930Z",
          "iopub.execute_input": "2025-08-17T18:47:40.323169Z",
          "iopub.status.idle": "2025-08-17T18:47:40.335324Z",
          "shell.execute_reply.started": "2025-08-17T18:47:40.323142Z",
          "shell.execute_reply": "2025-08-17T18:47:40.334688Z"
        },
        "id": "siR5tUpVia7T"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "val_ssim_c    = 0.0\n",
        "val_ms_ssim_c = 0.0\n",
        "val_psnr_c    = 0.0\n",
        "val_lpips_c   = 0.0\n",
        "\n",
        "val_ssim_g    = 0.0\n",
        "val_ms_ssim_g = 0.0\n",
        "val_psnr_g    = 0.0\n",
        "val_lpips_g   = 0.0\n",
        "\n",
        "total_inference_time = 0.0\n",
        "total_images = 0\n",
        "\n",
        "print(\"Running GAN on corrupted images...\")\n",
        "\n",
        "input_filenames = sorted(os.listdir(val_corrupted_dir))\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_idx, (corrupted, clean) in enumerate(tqdm(val_dataloader)):\n",
        "        if corrupted is None or clean is None:\n",
        "            continue\n",
        "        corrupted = corrupted.to(device).float()\n",
        "        clean = clean.to(device).float()\n",
        "\n",
        "        start_time = time.time()\n",
        "        fake = generator(corrupted).float()\n",
        "        end_time = time.time()\n",
        "\n",
        "        batch_time = (end_time - start_time)\n",
        "        total_inference_time += batch_time\n",
        "        total_images += corrupted.size(0)\n",
        "\n",
        "        fake_res      = rescale_to_01(fake)\n",
        "        clean_res     = rescale_to_01(clean)\n",
        "        corrupted_res = rescale_to_01(corrupted)\n",
        "\n",
        "        val_ssim_c      += (1 - ssim_loss(corrupted_res, clean_res)).item()\n",
        "        val_ms_ssim_c   += (1 - ms_ssim_loss(corrupted_res, clean_res)).item()\n",
        "        val_psnr_c      += psnr(corrupted_res, clean_res).item()\n",
        "        val_lpips_c     += lpips_model(corrupted_res * 2 - 1, clean_res * 2 - 1).mean().item()\n",
        "\n",
        "        val_ssim_g      += (1 - ssim_loss(fake_res, clean_res)).item()\n",
        "        val_ms_ssim_g   += (1 - ms_ssim_loss(fake_res, clean_res)).item()\n",
        "        val_psnr_g      += psnr(fake_res, clean_res).item()\n",
        "        val_lpips_g     += lpips_model(fake_res * 2 - 1, clean_res * 2 - 1).mean().item()\n",
        "\n",
        "        for i in range(fake_res.size(0)):\n",
        "            filename = input_filenames[batch_idx * val_dataloader.batch_size + i]\n",
        "            img_to_save = TF.to_pil_image(fake_res[i].cpu())\n",
        "            img_to_save.save(os.path.join(gen_dir, filename))\n",
        "\n",
        "\n",
        "val_ssim_c    /= len(val_dataloader)\n",
        "val_ms_ssim_c /= len(val_dataloader)\n",
        "val_psnr_c    /= len(val_dataloader)\n",
        "val_lpips_c   /= len(val_dataloader)\n",
        "\n",
        "val_ssim_g    /= len(val_dataloader)\n",
        "val_ms_ssim_g /= len(val_dataloader)\n",
        "val_psnr_g    /= len(val_dataloader)\n",
        "val_lpips_g   /= len(val_dataloader)\n",
        "\n",
        "avg_latency_per_image = total_inference_time / total_images\n",
        "avg_latency_per_batch = total_inference_time / len(val_dataloader)\n",
        "\n",
        "print(f\"Before GAN → SSIM: {val_ssim_c:.4f}, MS-SSIM: {val_ms_ssim_c:.4f}, PSNR: {val_psnr_c:.2f}, LPIPS: {val_lpips_c:.4f}\")\n",
        "print(f\"After GAN → SSIM: {val_ssim_g:.4f}, MS-SSIM: {val_ms_ssim_g:.4f}, PSNR: {val_psnr_g:.2f}, LPIPS: {val_lpips_g:.4f}\")\n",
        "print(f\"Avg inference latency → {avg_latency_per_image*1000:.2f} ms/image | {avg_latency_per_batch:.4f} s/batch\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-17T18:58:34.488195Z",
          "iopub.execute_input": "2025-08-17T18:58:34.488876Z",
          "iopub.status.idle": "2025-08-17T19:00:58.149986Z",
          "shell.execute_reply.started": "2025-08-17T18:58:34.488847Z",
          "shell.execute_reply": "2025-08-17T19:00:58.149188Z"
        },
        "id": "wRT8GRctia7T",
        "outputId": "b9b3f2e9-76e3-41b4-a549-660f0778c2a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Running GAN on corrupted images...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 321/321 [02:23<00:00,  2.23it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Before GAN → SSIM: 0.8076, MS-SSIM: 0.9185, PSNR: 22.09, LPIPS: 0.4203\nAfter GAN → SSIM: 0.9235, MS-SSIM: 0.9828, PSNR: 28.69, LPIPS: 0.0979\nAvg inference latency → 0.18 ms/image | 0.0059 s/batch\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from IPython.display import FileLink\n",
        "\n",
        "# Replace with your output folder path\n",
        "output_folder = \"/kaggle/working/generated\"\n",
        "\n",
        "# Create a zip archive of the output folder\n",
        "shutil.make_archive(\"generated_output_1\", \"zip\", output_folder)\n",
        "print(\"Output folder zipped as generated_output.zip\")\n",
        "\n",
        "# Display a clickable download link\n",
        "display(FileLink(\"generated_output_1.zip\"))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-17T17:25:32.070918Z",
          "iopub.execute_input": "2025-08-17T17:25:32.071257Z",
          "iopub.status.idle": "2025-08-17T17:25:35.767298Z",
          "shell.execute_reply.started": "2025-08-17T17:25:32.071232Z",
          "shell.execute_reply": "2025-08-17T17:25:35.766627Z"
        },
        "id": "LcuKDBNgia7U",
        "outputId": "f2399c46-ea25-4ce4-ccd6-c675f942657e"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Output folder zipped as generated_output.zip\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "/kaggle/working/generated_output_1.zip",
            "text/html": "<a href='generated_output_1.zip' target='_blank'>generated_output_1.zip</a><br>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    }
  ]
}